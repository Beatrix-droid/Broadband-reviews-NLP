{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Jupiter Notebook: \n",
    "gets the data scraped by the scrape.py scripts, creates dataframes from the lists and preprocesses for the machine learning model\n",
    "1. part 1: create the dataframe from the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scrape import customer_service_reviews, comments, dates, satisfaction_reviews, speed_reviews, reliability_reviews, customer_service_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all list values to a df:\n",
    "#create the dictionary that will make up the dataframe\n",
    "df_dict={\"Dates\": dates, \"Comments\": comments, \"Customer Service\": customer_service_reviews, \"Satisfaction Reviews\": satisfaction_reviews, \"Speed Reviews\": speed_reviews, \"Reliability Reviews\": reliability_reviews}\n",
    "\n",
    "#as certain columns are shorter than others use a trick to create a df with unequal arrays:https://stackoverflow.com/questions/19736080/creating-dataframe-from-a-dictionary-where-entries-have-different-lengths\n",
    "df = pd.DataFrame.from_dict(df_dict, orient='index')\n",
    "df=df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the dates columns from string to datetime object:\n",
    "df[\"Dates\"]= pd.to_datetime(df[\"Dates\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save date to csv:\n",
    "df.to_csv('raw_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. data cleaning: Dealing with the null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1960, 6)\n"
     ]
    }
   ],
   "source": [
    "#first read csv dropped unnamed columns and inspect the first few rows\n",
    "raw_df= pd.read_csv(\"raw_data.csv\")\n",
    "raw_df.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "print(raw_df.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Customer Service</th>\n",
       "      <th>Satisfaction Reviews</th>\n",
       "      <th>Speed Reviews</th>\n",
       "      <th>Reliability Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-15</td>\n",
       "      <td>Moved back to the UK end of August and got Vir...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-14</td>\n",
       "      <td>A truly attrocious service, both in terms of b...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>They make it as hard as they can for you to ca...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-11-11</td>\n",
       "      <td>Pay for the 350Mbps package but only ever mana...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-11-11</td>\n",
       "      <td>The worst customer service:\\r-The bots ask irr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dates                                           Comments  \\\n",
       "0  2022-11-15  Moved back to the UK end of August and got Vir...   \n",
       "1  2022-11-14  A truly attrocious service, both in terms of b...   \n",
       "2  2022-11-13  They make it as hard as they can for you to ca...   \n",
       "3  2022-11-11  Pay for the 350Mbps package but only ever mana...   \n",
       "4  2022-11-11  The worst customer service:\\r-The bots ask irr...   \n",
       "\n",
       "   Customer Service  Satisfaction Reviews  Speed Reviews  Reliability Reviews  \n",
       "0               1.0                   1.0            1.0                  1.0  \n",
       "1               1.0                   1.0            1.0                  1.0  \n",
       "2               1.0                   1.0            2.0                  2.0  \n",
       "3               1.0                   1.0            3.0                  2.0  \n",
       "4               1.0                   1.0            3.0                  2.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check if any of the comment rows are empty. If they are we are forced to drop this row as the main project revolves around nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['Comments'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop any reviews that have no text as of now use to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.dropna(subset=['Comments'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1959, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that rows with missing comments have been dropped lets look at the rest of the missing data. We will deal with the missing values bu using scikit learn's simple imputer, that will impute the missing data in each column for us accoprding the to the most common value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['Customer Service'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imputer = imputer.fit(raw_df[['Customer Service']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3b44d0901b27b90b29836124934e882c64ed863e8408c20b31f73c13ca8ef04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
