{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation\n",
    "\n",
    "In this jupyter notebook we shall look at taking the preprocessed data  generated by preprocessing_part_2.ipynb and creating machine learning model from it \n",
    "that reads each review and tries to predict what its average score is. Thus we are building a text classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start with the relevant imports\n",
    "\n",
    "#use to visualise the data \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#used to build the model\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, TextVectorization, Dropout, Embedding, LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import SparseCategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: load and inspect the csv with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first load the data with pandas\n",
    "df=pd.read_csv(\"./data/data_ready_for_model.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Average Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Moved back to the UK end of August and got Vir...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A truly attrocious service, both in terms of b...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>They make it as hard as they can for you to ca...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Pay for the 350Mbps package but only ever mana...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The worst customer service:\\r-The bots ask irr...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           Comments  \\\n",
       "0           0  Moved back to the UK end of August and got Vir...   \n",
       "1           1  A truly attrocious service, both in terms of b...   \n",
       "2           2  They make it as hard as they can for you to ca...   \n",
       "3           3  Pay for the 350Mbps package but only ever mana...   \n",
       "4           4  The worst customer service:\\r-The bots ask irr...   \n",
       "\n",
       "   Average Score  \n",
       "0            1.0  \n",
       "1            1.0  \n",
       "2            2.0  \n",
       "3            2.0  \n",
       "4            2.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Unnamed: 0\", axis=1, inplace=True) #unneeded column, resulted when csv was created from dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 prepare the data into train val test sets (code is borrowed from my Wine reviews classification Neural Network). We want our target ot be our \"average score\" and our features to be the \"comments\". We have quite the imbalanced dataset,  because we have more average scores with a score of 1 and two than any other score. Because we are implementing a classification model, this could be especially problematic.\n",
    "\n",
    "To overcome this data we will _stratify_ the data. This is to ensure that relative class frequencies is approximately preserved in each train and validation fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3473 434 435\n"
     ]
    }
   ],
   "source": [
    "train, val, test = np.split(df.sample(frac=1), [int(0.8*len(df)), int(0.9 * len(df))])\n",
    "print(len(train), len(val), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a function that feeds data to the model\n",
    "\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=1024):\n",
    "  df = dataframe.copy()\n",
    "  labels = df.pop('Average Score')\n",
    "  df = df[\"Comments\"]\n",
    "  ds = tf.data.Dataset.from_tensor_slices((df, labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating instances of our train, val test data\n",
    "train_data = df_to_dataset(train)\n",
    "valid_data = df_to_dataset(val)\n",
    "test_data = df_to_dataset(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the time for creating a neural network has finally arrived! First, let's encode our comments using a text vectorizor model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max tokens=max no of words we will remember.\n",
    "encoder=TextVectorization(max_tokens=2000)\n",
    "\n",
    "#train data is composed of comment and the score but we don't really \n",
    "# #need the score for this encoder. So just use a lambda function to pass in the text.\n",
    "encoder.adapt(train_data.map(lambda comment, score: comment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's check our vocabulary. These are just some of the words that have been encoded into vectors: (UNK) represents any unknown tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '[UNK]', 'to', 'the', 'i', 'and', 'a', 'they', 'for', 'of',\n",
       "       'is', 'my', 'have', 'virgin', 'it', 'service', 'with', 'was',\n",
       "       'that', 'in', 'you', 'not', 'on', 'me', 'customer', 'this', 'be',\n",
       "       'but', 'as', 'them', 'no', 'had', 'we', 'are', 'broadband', 'been',\n",
       "       'so', 'get', 'when', 'up', 'at', 'will', 'media', 'from', 'their',\n",
       "       'would', 'contract', 'all', 'phone', 'an'], dtype='<U15')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab=np.array(encoder.get_vocabulary())\n",
    "vocab[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        encoder,\n",
    "        Embedding(input_dim=len(encoder.get_vocabulary()), output_dim=32, mask_zero=True),#mask=0 so we can handle inputs of variable lengths\n",
    "        #now we have a vector of numbers a nn can comprehend\n",
    "        LSTM(32),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dropout(0.4),\n",
    "        Dense(5, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(learning_rate=0.001), \n",
    "             loss = SparseCategoricalCrossentropy(), #binarycross entropy as binary classification problem\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 6s 863ms/step - loss: 1.6118 - accuracy: 0.0890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.611752986907959, 0.0889720693230629]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_data) #evaluate performance of model without training it first\n",
    "#accuracy is around 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_data, epochs=50, validation_data=valid_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3b44d0901b27b90b29836124934e882c64ed863e8408c20b31f73c13ca8ef04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
