{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation\n",
    "\n",
    "In this jupyter notebook we shall look at taking the preprocessed data  generated by preprocessing_part_2.ipynb and creating machine learning model from it \n",
    "that reads each review and tries to predict what its average score is. Thus we are building a text classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start with the relevant imports\n",
    "\n",
    "#use to visualise the data \n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#used to build the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.losses import SparseCategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: load and inspect the csv with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first load the data with pandas\n",
    "df=pd.read_csv(\"./data/data_ready_for_model.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Average Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>moved uk end august got virgin media broadband...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>truly attrocious service terms broadband custo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>hard cancel contract. phone 2 hours t o spend ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>pay 350mbps package managed 250mbps upload 34 ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>worst customer service: -the bots ask irreleva...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>informed given upgrade difference speeds reboo...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>wish zero star virgin media unfortunately lowe...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>sold package 1gb speed 2 tivo box 6 ask act li...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>simply don't sold. example switching bt 67mb p...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>virgin worse broadband company. ive trying boo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           Comments  \\\n",
       "0           0  moved uk end august got virgin media broadband...   \n",
       "1           1  truly attrocious service terms broadband custo...   \n",
       "2           2  hard cancel contract. phone 2 hours t o spend ...   \n",
       "3           3  pay 350mbps package managed 250mbps upload 34 ...   \n",
       "4           4  worst customer service: -the bots ask irreleva...   \n",
       "5           5  informed given upgrade difference speeds reboo...   \n",
       "6           6  wish zero star virgin media unfortunately lowe...   \n",
       "7           7  sold package 1gb speed 2 tivo box 6 ask act li...   \n",
       "8           8  simply don't sold. example switching bt 67mb p...   \n",
       "9           9  virgin worse broadband company. ive trying boo...   \n",
       "\n",
       "   Average Score  \n",
       "0            1.0  \n",
       "1            1.0  \n",
       "2            2.0  \n",
       "3            2.0  \n",
       "4            2.0  \n",
       "5            3.0  \n",
       "6            1.0  \n",
       "7            2.0  \n",
       "8            3.0  \n",
       "9            1.0  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Unnamed: 0\", axis=1, inplace=True) #unneeded column, resulted when csv was created from dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step before splitting our data into train test split sets is to tokenize the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max words to be used.\n",
    "max_words=5000 \n",
    "#max no of words per complaint:\n",
    "max_sequence=250\n",
    "#fixed\n",
    "embedding_dim=250\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(df[\"Comments\"].values)\n",
    "word_index=tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truncate and pad the input sequences so that they are all in the same length for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 12592 unique tokens\n"
     ]
    }
   ],
   "source": [
    "print(f\"found {len(word_index)} unique tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (4342, 250)\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(df['Comments'].values)\n",
    "X = tf.keras.utils.pad_sequences(X, maxlen=max_sequence)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 prepare the data into train val test sets (code is borrowed from my Wine reviews classification Neural Network). We want our target ot be our \"average score\" and our features to be the \"comments\". We have quite the imbalanced dataset,  because we have more average scores with a score of 1 and two than any other score. Because we are implementing a classification model, this could be especially problematic.\n",
    "\n",
    "To overcome this data we will _stratify_ the data. This is to ensure that relative class frequencies is approximately preserved in each train and validation fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df[\"Average Score\"]\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.340, random_state=0, stratify=y)\n",
    "#60 training, 20 validation, 20 testing\n",
    "X_val, X_test, y_val, y_test =train_test_split(X_temp, y_temp, test_size = 0.5, random_state=0, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the time for creating a neural network has finally arrived! First, let's encode our comments using a text vectorizor model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's check our vocabulary. These are just some of the words that have been encoded into vectors: (UNK) represents any unknown tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        Embedding(max_words, embedding_dim, input_length=X.shape[1]),#mask=0 so we can handle inputs of variable lengths\n",
    "        #now we have a vector of numbers a nn can comprehend\n",
    "        tf.keras.layers.SpatialDropout1D(0.2),\n",
    "        tf.keras.layers.LSTM(32),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dropout(0.4),\n",
    "        Dense(5, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "             ModelCheckpoint(filepath='saved_model', monitor='val_loss', save_best_only=True)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(RMSprop(learning_rate=0.001), \n",
    "             loss = SparseCategoricalCrossentropy(), #categorical cross entropy as multi classification problem\n",
    "                metrics=[\"sparse_categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 4s 35ms/step - loss: 1.6114 - sparse_categorical_accuracy: 0.1194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.611374020576477, 0.11937172710895538]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train) #evaluate performance of model without training it first\n",
    "#accuracy is around 0.36.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 1.0164 - sparse_categorical_accuracy: 0.6230"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 17s 161ms/step - loss: 1.0164 - sparse_categorical_accuracy: 0.6230 - val_loss: 0.8620 - val_sparse_categorical_accuracy: 0.6491\n",
      "Epoch 2/50\n",
      "90/90 [==============================] - 12s 131ms/step - loss: 0.8811 - sparse_categorical_accuracy: 0.6360 - val_loss: 0.8640 - val_sparse_categorical_accuracy: 0.6491\n",
      "Epoch 3/50\n",
      "90/90 [==============================] - 12s 129ms/step - loss: 0.7998 - sparse_categorical_accuracy: 0.6565 - val_loss: 0.9013 - val_sparse_categorical_accuracy: 0.6531\n",
      "Epoch 4/50\n",
      "90/90 [==============================] - 12s 128ms/step - loss: 0.6916 - sparse_categorical_accuracy: 0.7082 - val_loss: 1.0129 - val_sparse_categorical_accuracy: 0.6206\n",
      "Epoch 5/50\n",
      "90/90 [==============================] - 12s 129ms/step - loss: 0.5610 - sparse_categorical_accuracy: 0.7742 - val_loss: 1.1174 - val_sparse_categorical_accuracy: 0.5583\n",
      "Epoch 6/50\n",
      "90/90 [==============================] - 11s 126ms/step - loss: 0.4535 - sparse_categorical_accuracy: 0.8311 - val_loss: 1.3090 - val_sparse_categorical_accuracy: 0.4458\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/model1\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"saved_model/model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    2819\n",
       "1.0    1227\n",
       "3.0     275\n",
       "4.0      21\n",
       "Name: Average Score, dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Average Score\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model has trained but has a val accuracy of only 0.6531. We can see that it is clearly overfitting. We have quite an imbalanced dataset, that we need to account for. Lots of 2.0 star reviews and very few  3 and 4 start reviews.\n",
    "\n",
    "\n",
    "To increase the accuracy, it might be worth merging the two smallest classes together with a combined rating of 3.5:\n",
    "\n",
    "In addition, to tackle the large number of 2.0 and 1.0 start reviews, we will be using Jaccard's similarity to look for reviews that are similar to each other enough to be counted as duplicates and then remove them. jaccard's similarity is a mathematical function that just does that: measures how similar two sets are to each other.\n",
    "\n",
    "First, let's address the two smaller classes and merge them together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge smallest classes in the df  #softmax will now be 3 classes\n",
    "condition = df['Average Score']== 4\n",
    "df.loc[condition, 'Average Score'] = 3.5\n",
    "condition = df['Average Score']== 3\n",
    "df.loc[condition, 'Average Score'] = 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    2819\n",
       "1.0    1227\n",
       "3.5     296\n",
       "Name: Average Score, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Average Score\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's deal with the comments. First tokenize the comments column and define the jaccard function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = lambda doc: doc.lower().split(\" \")\n",
    "tokenized_documents = [tokenize(d) for d in df[\"Comments\"]] # tokenized docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wish', 'zero', 'star', 'virgin', 'media', 'unfortunately', 'lowest', 'star', '1.', 'intend', 'joining', 'network', \"don't\", 'want', 'bills', 'increasing', 'informed', \"don't\", 'mistake', 'joing', 'virgin', 'media.', 'set', 'liars', 'lied', '2019', 'join', 'network', 'pay', '33', 'pounds', '18', 'month', 'contract.', '4', 'month', 'virgin', 'media', 'increase', 'price', '59', 'pounds', 'month', \"wasn't\", 'initially', 'told', 'me.', 'realised', \"they've\", 'increased', 'monthly', 'end', 'contract', 'ended', 'contract', '102.27', 'insisted', 'pay', 'began', 'send', 'debt', 'collector', 'disturb', 'payment', 'spoilt', 'credit', 'rating', 'reported', 'case', 'credit', 'authority', 'credit', 'affected', 'them.', 'love', 'credit', 'report', \"don't\", 'want', 'paying', 'extra', 'bills', 'comparison', 'initially', 'agree', \"don't\", 'join', 'virgin', 'media.', 'lastly', 'saw', \"they've\", 'gone', 'bit', 'spoil', 'credit', 'report', 'contacted', 'voice', 'complain', 'customer', 'service', 'listened', 'complain', 'confirmed', 'bills', 'written', 'online', 'chat', 'service', '2', 'weeks', 'confirming', 'written', 'came', 'meant', 'payment', '102.27.', 'showed', 'evidence', 'confirms', 'written', 'said', 'written', 'means', 'pay.', 'wonder', 'stupid', 'people', 'taught', 'tricking', 'kid.', 'conclusion', 'love', 'credit', 'score', \"don't\", 'want', 'excessive', 'bills', 'certain', 'month', 'joining', 'network', \"don't\", 'attempt', 'joining', 'virgin', 'media', 'liars', 'looking', 'ways', 'extort', 'customers.']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_documents[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(query: set, document: set) -> float:\n",
    "    \n",
    "    \"\"\"\"Returns the Jaccard similarity between a query and a specified document\"\"\"\n",
    "\n",
    "    intersection = set(query).intersection(set(document))\n",
    "    union = set(query).union(set(document))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply this measure to the comments column! As the most common score is the one with an average of two, we will try and eliminate reviews that have comments that have two star ratings, or at least look like they could have two star ratings.\n",
    "\n",
    "To do this, I will (arbitrarily) pick the first comment that has a 2 star review and compare the rest of the comments in the dataframe to this one using the Jaccardian metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "values=[]\n",
    "def jaccard_similarity(query: set) -> float:\n",
    "    \n",
    "    \"\"\"\"Returns the Jaccard similarity between a query and a specified document\"\"\"\n",
    "\n",
    "    intersection = set(query).intersection(set(df[\"Comments\"][0]))\n",
    "    union = set(query).union(set(df[\"Comments\"][0]))\n",
    "    values.append(len(intersection)/len(union))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       None\n",
       "1       None\n",
       "2       None\n",
       "3       None\n",
       "4       None\n",
       "        ... \n",
       "4337    None\n",
       "4338    None\n",
       "4339    None\n",
       "4340    None\n",
       "4341    None\n",
       "Name: Comments, Length: 4342, dtype: object"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Comments\"].apply(jaccard_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.7027027027027027,\n",
       " 0.6666666666666666,\n",
       " 0.6923076923076923,\n",
       " 0.6923076923076923,\n",
       " 0.5277777777777778,\n",
       " 0.825,\n",
       " 0.6486486486486487,\n",
       " 0.7142857142857143,\n",
       " 0.6756756756756757,\n",
       " 0.7631578947368421,\n",
       " 0.7297297297297297,\n",
       " 0.6756756756756757,\n",
       " 0.7631578947368421,\n",
       " 0.5,\n",
       " 0.4166666666666667,\n",
       " 0.7631578947368421,\n",
       " 0.6486486486486487,\n",
       " 0.7,\n",
       " 0.7894736842105263,\n",
       " 0.6,\n",
       " 0.8378378378378378,\n",
       " 0.7692307692307693,\n",
       " 0.7368421052631579,\n",
       " 0.7567567567567568,\n",
       " 0.6923076923076923,\n",
       " 0.7222222222222222,\n",
       " 0.775,\n",
       " 0.6410256410256411,\n",
       " 0.5675675675675675,\n",
       " 0.6578947368421053,\n",
       " 0.6486486486486487,\n",
       " 0.6578947368421053,\n",
       " 0.5555555555555556,\n",
       " 0.825,\n",
       " 0.6944444444444444,\n",
       " 0.3888888888888889,\n",
       " 0.6585365853658537,\n",
       " 0.6666666666666666,\n",
       " 0.5555555555555556,\n",
       " 0.7027027027027027,\n",
       " 0.7222222222222222,\n",
       " 0.717948717948718,\n",
       " 0.631578947368421,\n",
       " 0.6756756756756757,\n",
       " 0.5833333333333334,\n",
       " 0.6578947368421053,\n",
       " 0.5405405405405406,\n",
       " 0.75,\n",
       " 0.6944444444444444,\n",
       " 0.7380952380952381,\n",
       " 0.7631578947368421,\n",
       " 0.6944444444444444,\n",
       " 0.6923076923076923,\n",
       " 0.7567567567567568,\n",
       " 0.5277777777777778,\n",
       " 0.5945945945945946,\n",
       " 0.6842105263157895,\n",
       " 0.8461538461538461,\n",
       " 0.7837837837837838,\n",
       " 0.7368421052631579,\n",
       " 0.8108108108108109,\n",
       " 0.6388888888888888,\n",
       " 0.5833333333333334,\n",
       " 0.7297297297297297,\n",
       " 0.7105263157894737,\n",
       " 0.6842105263157895,\n",
       " 0.4722222222222222,\n",
       " 0.631578947368421,\n",
       " 0.5897435897435898,\n",
       " 0.6944444444444444,\n",
       " 0.7567567567567568,\n",
       " 0.6756756756756757,\n",
       " 0.6388888888888888,\n",
       " 0.5833333333333334,\n",
       " 0.7837837837837838,\n",
       " 0.6486486486486487,\n",
       " 0.7,\n",
       " 0.6756756756756757,\n",
       " 0.7567567567567568,\n",
       " 0.717948717948718,\n",
       " 0.6052631578947368,\n",
       " 0.6842105263157895,\n",
       " 0.6744186046511628,\n",
       " 0.5555555555555556,\n",
       " 0.7027027027027027,\n",
       " 0.6666666666666666,\n",
       " 0.5,\n",
       " 0.6756756756756757,\n",
       " 0.6666666666666666,\n",
       " 0.7105263157894737,\n",
       " 0.5405405405405406,\n",
       " 0.6486486486486487,\n",
       " 0.6410256410256411,\n",
       " 0.6216216216216216,\n",
       " 0.6842105263157895,\n",
       " 0.5833333333333334,\n",
       " 0.5897435897435898,\n",
       " 0.7027027027027027,\n",
       " 0.5675675675675675,\n",
       " 0.5526315789473685,\n",
       " 0.6111111111111112,\n",
       " 0.7027027027027027,\n",
       " 0.6756756756756757,\n",
       " 0.6756756756756757,\n",
       " 0.5526315789473685,\n",
       " 0.6944444444444444,\n",
       " 0.5897435897435898,\n",
       " 0.7435897435897436,\n",
       " 0.6923076923076923,\n",
       " 0.5405405405405406,\n",
       " 0.631578947368421,\n",
       " 0.7777777777777778,\n",
       " 0.75,\n",
       " 0.7567567567567568,\n",
       " 0.6388888888888888,\n",
       " 0.7435897435897436,\n",
       " 0.6944444444444444,\n",
       " 0.7222222222222222,\n",
       " 0.6756756756756757,\n",
       " 0.5833333333333334,\n",
       " 0.6388888888888888,\n",
       " 0.7674418604651163,\n",
       " 0.6923076923076923,\n",
       " 0.7777777777777778,\n",
       " 0.5277777777777778,\n",
       " 0.8378378378378378,\n",
       " 0.6388888888888888,\n",
       " 0.7105263157894737,\n",
       " 0.6388888888888888,\n",
       " 0.5945945945945946,\n",
       " 0.6666666666666666,\n",
       " 0.6842105263157895,\n",
       " 0.6944444444444444,\n",
       " 0.6486486486486487,\n",
       " 0.65,\n",
       " 0.7,\n",
       " 0.6578947368421053,\n",
       " 0.6756756756756757,\n",
       " 0.7894736842105263,\n",
       " 0.75,\n",
       " 0.75,\n",
       " 0.8,\n",
       " 0.725,\n",
       " 0.7435897435897436,\n",
       " 0.8611111111111112,\n",
       " 0.6153846153846154,\n",
       " 0.6923076923076923,\n",
       " 0.6111111111111112,\n",
       " 0.6216216216216216,\n",
       " 0.8611111111111112,\n",
       " 0.717948717948718,\n",
       " 0.6578947368421053,\n",
       " 0.7105263157894737,\n",
       " 0.65,\n",
       " 0.5833333333333334,\n",
       " 0.7692307692307693,\n",
       " 0.5405405405405406,\n",
       " 0.6153846153846154,\n",
       " 0.6111111111111112,\n",
       " 0.6944444444444444,\n",
       " 0.717391304347826,\n",
       " 0.6756756756756757,\n",
       " 0.7222222222222222,\n",
       " 0.7297297297297297,\n",
       " 0.6388888888888888,\n",
       " 0.717948717948718,\n",
       " 0.7368421052631579,\n",
       " 0.7837837837837838,\n",
       " 0.6388888888888888,\n",
       " 0.6410256410256411,\n",
       " 0.7368421052631579,\n",
       " 0.631578947368421,\n",
       " 0.7027027027027027,\n",
       " 0.6923076923076923,\n",
       " 0.7368421052631579,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.6388888888888888,\n",
       " 0.7368421052631579,\n",
       " 0.7142857142857143,\n",
       " 0.7368421052631579,\n",
       " 0.717948717948718,\n",
       " 0.6842105263157895,\n",
       " 0.6944444444444444,\n",
       " 0.775,\n",
       " 0.725,\n",
       " 0.75,\n",
       " 0.6842105263157895,\n",
       " 0.6486486486486487,\n",
       " 0.5405405405405406,\n",
       " 0.6216216216216216,\n",
       " 0.7,\n",
       " 0.7368421052631579,\n",
       " 0.6756756756756757,\n",
       " 0.6944444444444444,\n",
       " 0.7368421052631579,\n",
       " 0.717948717948718,\n",
       " 0.4166666666666667,\n",
       " 0.5555555555555556,\n",
       " 0.7894736842105263,\n",
       " 0.7027027027027027,\n",
       " 0.6585365853658537,\n",
       " 0.7027027027027027,\n",
       " 0.75,\n",
       " 0.6666666666666666,\n",
       " 0.7297297297297297,\n",
       " 0.6578947368421053,\n",
       " 0.7368421052631579,\n",
       " 0.7435897435897436,\n",
       " 0.7105263157894737,\n",
       " 0.4722222222222222,\n",
       " 0.7317073170731707,\n",
       " 0.6666666666666666,\n",
       " 0.631578947368421,\n",
       " 0.4444444444444444,\n",
       " 0.6388888888888888,\n",
       " 0.6410256410256411,\n",
       " 0.6216216216216216,\n",
       " 0.75,\n",
       " 0.6111111111111112,\n",
       " 0.6666666666666666,\n",
       " 0.631578947368421,\n",
       " 0.6756756756756757,\n",
       " 0.725,\n",
       " 0.6388888888888888,\n",
       " 0.7222222222222222,\n",
       " 0.75,\n",
       " 0.825,\n",
       " 0.8157894736842105,\n",
       " 0.717948717948718,\n",
       " 0.4864864864864865,\n",
       " 0.6388888888888888,\n",
       " 0.6153846153846154,\n",
       " 0.6842105263157895,\n",
       " 0.6842105263157895,\n",
       " 0.7297297297297297,\n",
       " 0.7297297297297297,\n",
       " 0.725,\n",
       " 0.7222222222222222,\n",
       " 0.4444444444444444,\n",
       " 0.6410256410256411,\n",
       " 0.6388888888888888,\n",
       " 0.7777777777777778,\n",
       " 0.5833333333333334,\n",
       " 0.6388888888888888,\n",
       " 0.6666666666666666,\n",
       " 0.7837837837837838,\n",
       " 0.6666666666666666,\n",
       " 0.5833333333333334,\n",
       " 0.7567567567567568,\n",
       " 0.7027027027027027,\n",
       " 0.7073170731707317,\n",
       " 0.5555555555555556,\n",
       " 0.7560975609756098,\n",
       " 0.7,\n",
       " 0.7105263157894737,\n",
       " 0.7435897435897436,\n",
       " 0.8048780487804879,\n",
       " 0.5833333333333334,\n",
       " 0.7105263157894737,\n",
       " 0.8333333333333334,\n",
       " 0.6578947368421053,\n",
       " 0.7631578947368421,\n",
       " 0.6944444444444444,\n",
       " 0.7380952380952381,\n",
       " 0.6666666666666666,\n",
       " 0.6976744186046512,\n",
       " 0.7948717948717948,\n",
       " 0.7222222222222222,\n",
       " 0.7317073170731707,\n",
       " 0.5526315789473685,\n",
       " 0.6666666666666666,\n",
       " 0.7105263157894737,\n",
       " 0.8157894736842105,\n",
       " 0.6666666666666666,\n",
       " 0.717948717948718,\n",
       " 0.7317073170731707,\n",
       " 0.5833333333333334,\n",
       " 0.6052631578947368,\n",
       " 0.7105263157894737,\n",
       " 0.7894736842105263,\n",
       " 0.6578947368421053,\n",
       " 0.7894736842105263,\n",
       " 0.7027027027027027,\n",
       " 0.6216216216216216,\n",
       " 0.5384615384615384,\n",
       " 0.7105263157894737,\n",
       " 0.6486486486486487,\n",
       " 0.6216216216216216,\n",
       " 0.6486486486486487,\n",
       " 0.6388888888888888,\n",
       " 0.6842105263157895,\n",
       " 0.7380952380952381,\n",
       " 0.7368421052631579,\n",
       " 0.5555555555555556,\n",
       " 0.7317073170731707,\n",
       " 0.7837837837837838,\n",
       " 0.631578947368421,\n",
       " 0.6052631578947368,\n",
       " 0.631578947368421,\n",
       " 0.7948717948717948,\n",
       " 0.7727272727272727,\n",
       " 0.5675675675675675,\n",
       " 0.6944444444444444,\n",
       " 0.6578947368421053,\n",
       " 0.6923076923076923,\n",
       " 0.7555555555555555,\n",
       " 0.7692307692307693,\n",
       " 0.631578947368421,\n",
       " 0.7222222222222222,\n",
       " 0.6944444444444444,\n",
       " 0.6756756756756757,\n",
       " 0.6944444444444444,\n",
       " 0.6923076923076923,\n",
       " 0.6486486486486487,\n",
       " 0.5555555555555556,\n",
       " 0.7027027027027027,\n",
       " 0.7692307692307693,\n",
       " 0.5555555555555556,\n",
       " 0.75,\n",
       " 0.5675675675675675,\n",
       " 0.6388888888888888,\n",
       " 0.3888888888888889,\n",
       " 0.7027027027027027,\n",
       " 0.5277777777777778,\n",
       " 0.6842105263157895,\n",
       " 0.5277777777777778,\n",
       " 0.6842105263157895,\n",
       " 0.8055555555555556,\n",
       " 0.7297297297297297,\n",
       " 0.7222222222222222,\n",
       " 0.6111111111111112,\n",
       " 0.6388888888888888,\n",
       " 0.8048780487804879,\n",
       " 0.6944444444444444,\n",
       " 0.6944444444444444,\n",
       " 0.6388888888888888,\n",
       " 0.6842105263157895,\n",
       " 0.8378378378378378,\n",
       " 0.6944444444444444,\n",
       " 0.7297297297297297,\n",
       " 0.6486486486486487,\n",
       " 0.6216216216216216,\n",
       " 0.6944444444444444,\n",
       " 0.75,\n",
       " 0.5833333333333334,\n",
       " 0.8095238095238095,\n",
       " 0.6944444444444444,\n",
       " 0.7222222222222222,\n",
       " 0.6111111111111112,\n",
       " 0.6388888888888888,\n",
       " 0.7368421052631579,\n",
       " 0.6,\n",
       " 0.5833333333333334,\n",
       " 0.7027027027027027,\n",
       " 0.6666666666666666,\n",
       " 0.6842105263157895,\n",
       " 0.7435897435897436,\n",
       " 0.6666666666666666,\n",
       " 0.7894736842105263,\n",
       " 0.7368421052631579,\n",
       " 0.7894736842105263,\n",
       " 0.6578947368421053,\n",
       " 0.7027027027027027,\n",
       " 0.775,\n",
       " 0.6052631578947368,\n",
       " 0.7631578947368421,\n",
       " 0.6944444444444444,\n",
       " 0.6216216216216216,\n",
       " 0.5555555555555556,\n",
       " 0.7222222222222222,\n",
       " 0.775,\n",
       " 0.7948717948717948,\n",
       " 0.7631578947368421,\n",
       " 0.7567567567567568,\n",
       " 0.631578947368421,\n",
       " 0.8333333333333334,\n",
       " 0.6486486486486487,\n",
       " 0.6666666666666666,\n",
       " 0.6829268292682927,\n",
       " 0.6388888888888888,\n",
       " 0.4722222222222222,\n",
       " 0.6578947368421053,\n",
       " 0.717948717948718,\n",
       " 0.7142857142857143,\n",
       " 0.5277777777777778,\n",
       " 0.7692307692307693,\n",
       " 0.6578947368421053,\n",
       " 0.7948717948717948,\n",
       " 0.717948717948718,\n",
       " 0.7222222222222222,\n",
       " 0.5555555555555556,\n",
       " 0.7297297297297297,\n",
       " 0.6388888888888888,\n",
       " 0.7222222222222222,\n",
       " 0.6756756756756757,\n",
       " 0.7317073170731707,\n",
       " 0.5526315789473685,\n",
       " 0.7027027027027027,\n",
       " 0.7222222222222222,\n",
       " 0.725,\n",
       " 0.7567567567567568,\n",
       " 0.7297297297297297,\n",
       " 0.7297297297297297,\n",
       " 0.6052631578947368,\n",
       " 0.5,\n",
       " 0.75,\n",
       " 0.6111111111111112,\n",
       " 0.7317073170731707,\n",
       " 0.7567567567567568,\n",
       " 0.8,\n",
       " 0.775,\n",
       " 0.7105263157894737,\n",
       " 0.717948717948718,\n",
       " 0.4722222222222222,\n",
       " 0.7027027027027027,\n",
       " 0.7631578947368421,\n",
       " 0.6842105263157895,\n",
       " 0.717948717948718,\n",
       " 0.675,\n",
       " 0.6578947368421053,\n",
       " 0.8055555555555556,\n",
       " 0.5945945945945946,\n",
       " 0.6756756756756757,\n",
       " 0.6216216216216216,\n",
       " 0.6111111111111112,\n",
       " 0.6410256410256411,\n",
       " 0.6666666666666666,\n",
       " 0.631578947368421,\n",
       " 0.6216216216216216,\n",
       " 0.6388888888888888,\n",
       " 0.717948717948718,\n",
       " 0.7297297297297297,\n",
       " 0.7631578947368421,\n",
       " 0.7105263157894737,\n",
       " 0.6666666666666666,\n",
       " 0.6111111111111112,\n",
       " 0.6486486486486487,\n",
       " 0.7631578947368421,\n",
       " 0.5833333333333334,\n",
       " 0.5277777777777778,\n",
       " 0.7435897435897436,\n",
       " 0.8108108108108109,\n",
       " 0.6410256410256411,\n",
       " 0.75,\n",
       " 0.5833333333333334,\n",
       " 0.7567567567567568,\n",
       " 0.675,\n",
       " 0.6842105263157895,\n",
       " 0.6216216216216216,\n",
       " 0.6666666666666666,\n",
       " 0.6341463414634146,\n",
       " 0.3783783783783784,\n",
       " 0.6842105263157895,\n",
       " 0.7777777777777778,\n",
       " 0.7435897435897436,\n",
       " 0.725,\n",
       " 0.6944444444444444,\n",
       " 0.75,\n",
       " 0.5897435897435898,\n",
       " 0.575,\n",
       " 0.7777777777777778,\n",
       " 0.6486486486486487,\n",
       " 0.5384615384615384,\n",
       " 0.7631578947368421,\n",
       " 0.8055555555555556,\n",
       " 0.7948717948717948,\n",
       " 0.6842105263157895,\n",
       " 0.8421052631578947,\n",
       " 0.7837837837837838,\n",
       " 0.6666666666666666,\n",
       " 0.5945945945945946,\n",
       " 0.7222222222222222,\n",
       " 0.6388888888888888,\n",
       " 0.5945945945945946,\n",
       " 0.631578947368421,\n",
       " 0.7619047619047619,\n",
       " 0.7297297297297297,\n",
       " 0.7567567567567568,\n",
       " 0.5555555555555556,\n",
       " 0.6756756756756757,\n",
       " 0.6904761904761905,\n",
       " 0.6578947368421053,\n",
       " 0.75,\n",
       " 0.6944444444444444,\n",
       " 0.7027027027027027,\n",
       " 0.8378378378378378,\n",
       " 0.7027027027027027,\n",
       " 0.6666666666666666,\n",
       " 0.8,\n",
       " 0.7,\n",
       " 0.6842105263157895,\n",
       " 0.825,\n",
       " 0.6578947368421053,\n",
       " 0.6666666666666666,\n",
       " 0.7105263157894737,\n",
       " 0.6666666666666666,\n",
       " 0.7567567567567568,\n",
       " 0.825,\n",
       " 0.7297297297297297,\n",
       " 0.6756756756756757,\n",
       " 0.6842105263157895,\n",
       " 0.7380952380952381,\n",
       " 0.6388888888888888,\n",
       " 0.7297297297297297,\n",
       " 0.7027027027027027,\n",
       " 0.6216216216216216,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.6486486486486487,\n",
       " 0.75,\n",
       " 0.5555555555555556,\n",
       " 0.625,\n",
       " 0.6052631578947368,\n",
       " 0.7435897435897436,\n",
       " 0.6666666666666666,\n",
       " 0.7222222222222222,\n",
       " 0.7777777777777778,\n",
       " 0.6486486486486487,\n",
       " 0.7222222222222222,\n",
       " 0.6904761904761905,\n",
       " 0.6153846153846154,\n",
       " 0.7222222222222222,\n",
       " 0.6486486486486487,\n",
       " 0.7297297297297297,\n",
       " 0.7435897435897436,\n",
       " 0.7297297297297297,\n",
       " 0.7567567567567568,\n",
       " 0.5833333333333334,\n",
       " 0.717948717948718,\n",
       " 0.6578947368421053,\n",
       " 0.7435897435897436,\n",
       " 0.7435897435897436,\n",
       " 0.6756756756756757,\n",
       " 0.725,\n",
       " 0.6944444444444444,\n",
       " 0.7368421052631579,\n",
       " 0.825,\n",
       " 0.6578947368421053,\n",
       " 0.7894736842105263,\n",
       " 0.7,\n",
       " 0.7222222222222222,\n",
       " 0.7777777777777778,\n",
       " 0.7317073170731707,\n",
       " 0.8205128205128205,\n",
       " 0.5789473684210527,\n",
       " 0.6097560975609756,\n",
       " 0.7317073170731707,\n",
       " 0.75,\n",
       " 0.6944444444444444,\n",
       " 0.6666666666666666,\n",
       " 0.6216216216216216,\n",
       " 0.7948717948717948,\n",
       " 0.7894736842105263,\n",
       " 0.7368421052631579,\n",
       " 0.6111111111111112,\n",
       " 0.7567567567567568,\n",
       " 0.6388888888888888,\n",
       " 0.7368421052631579,\n",
       " 0.6944444444444444,\n",
       " 0.7837837837837838,\n",
       " 0.6756756756756757,\n",
       " 0.8095238095238095,\n",
       " 0.6842105263157895,\n",
       " 0.7,\n",
       " 0.5555555555555556,\n",
       " 0.7692307692307693,\n",
       " 0.5641025641025641,\n",
       " 0.6578947368421053,\n",
       " 0.7368421052631579,\n",
       " 0.6216216216216216,\n",
       " 0.6842105263157895,\n",
       " 0.6944444444444444,\n",
       " 0.7368421052631579,\n",
       " 0.6829268292682927,\n",
       " 0.5945945945945946,\n",
       " 0.6111111111111112,\n",
       " 0.7894736842105263,\n",
       " 0.7894736842105263,\n",
       " 0.7027027027027027,\n",
       " 0.7222222222222222,\n",
       " 0.6666666666666666,\n",
       " 0.7560975609756098,\n",
       " 0.6666666666666666,\n",
       " 0.7027027027027027,\n",
       " 0.75,\n",
       " 0.6944444444444444,\n",
       " 0.7435897435897436,\n",
       " 0.631578947368421,\n",
       " 0.7567567567567568,\n",
       " 0.6829268292682927,\n",
       " 0.7222222222222222,\n",
       " 0.6410256410256411,\n",
       " 0.7222222222222222,\n",
       " 0.5555555555555556,\n",
       " 0.7317073170731707,\n",
       " 0.7777777777777778,\n",
       " 0.6756756756756757,\n",
       " 0.7674418604651163,\n",
       " 0.7567567567567568,\n",
       " 0.6756756756756757,\n",
       " 0.6923076923076923,\n",
       " 0.6388888888888888,\n",
       " 0.7073170731707317,\n",
       " 0.8055555555555556,\n",
       " 0.6410256410256411,\n",
       " 0.6842105263157895,\n",
       " 0.6486486486486487,\n",
       " 0.7560975609756098,\n",
       " 0.7297297297297297,\n",
       " 0.7027027027027027,\n",
       " 0.7837837837837838,\n",
       " 0.725,\n",
       " 0.631578947368421,\n",
       " 0.6666666666666666,\n",
       " 0.7,\n",
       " 0.6578947368421053,\n",
       " 0.6944444444444444,\n",
       " 0.6923076923076923,\n",
       " 0.6818181818181818,\n",
       " 0.5135135135135135,\n",
       " 0.7368421052631579,\n",
       " 0.7560975609756098,\n",
       " 0.6666666666666666,\n",
       " 0.813953488372093,\n",
       " 0.7567567567567568,\n",
       " 0.7894736842105263,\n",
       " 0.7837837837837838,\n",
       " 0.6756756756756757,\n",
       " 0.6756756756756757,\n",
       " 0.6216216216216216,\n",
       " 0.7567567567567568,\n",
       " 0.6666666666666666,\n",
       " 0.5555555555555556,\n",
       " 0.717948717948718,\n",
       " 0.7027027027027027,\n",
       " 0.6666666666666666,\n",
       " 0.6756756756756757,\n",
       " 0.8055555555555556,\n",
       " 0.775,\n",
       " 0.6410256410256411,\n",
       " 0.6578947368421053,\n",
       " 0.7380952380952381,\n",
       " 0.7567567567567568,\n",
       " 0.8108108108108109,\n",
       " 0.6756756756756757,\n",
       " 0.6388888888888888,\n",
       " 0.6486486486486487,\n",
       " 0.7435897435897436,\n",
       " 0.6842105263157895,\n",
       " 0.7222222222222222,\n",
       " 0.6904761904761905,\n",
       " 0.6578947368421053,\n",
       " 0.5555555555555556,\n",
       " 0.825,\n",
       " 0.6190476190476191,\n",
       " 0.725,\n",
       " 0.6578947368421053,\n",
       " 0.3611111111111111,\n",
       " 0.6944444444444444,\n",
       " 0.6410256410256411,\n",
       " 0.6756756756756757,\n",
       " 0.6388888888888888,\n",
       " 0.6052631578947368,\n",
       " 0.75,\n",
       " 0.7,\n",
       " 0.6666666666666666,\n",
       " 0.6923076923076923,\n",
       " 0.6829268292682927,\n",
       " 0.625,\n",
       " 0.7222222222222222,\n",
       " 0.6666666666666666,\n",
       " 0.6388888888888888,\n",
       " 0.717948717948718,\n",
       " 0.8048780487804879,\n",
       " 0.6216216216216216,\n",
       " 0.5789473684210527,\n",
       " 0.6904761904761905,\n",
       " 0.8,\n",
       " 0.7692307692307693,\n",
       " 0.7222222222222222,\n",
       " 0.6097560975609756,\n",
       " 0.6341463414634146,\n",
       " 0.7567567567567568,\n",
       " 0.7368421052631579,\n",
       " 0.8,\n",
       " 0.8048780487804879,\n",
       " 0.8108108108108109,\n",
       " 0.8055555555555556,\n",
       " 0.8648648648648649,\n",
       " 0.717948717948718,\n",
       " 0.7727272727272727,\n",
       " 0.6410256410256411,\n",
       " 0.6578947368421053,\n",
       " 0.7894736842105263,\n",
       " 0.717948717948718,\n",
       " 0.6756756756756757,\n",
       " 0.7894736842105263,\n",
       " 0.7317073170731707,\n",
       " 0.7567567567567568,\n",
       " 0.6756756756756757,\n",
       " 0.7317073170731707,\n",
       " 0.7692307692307693,\n",
       " 0.6666666666666666,\n",
       " 0.717948717948718,\n",
       " 0.5789473684210527,\n",
       " 0.6666666666666666,\n",
       " 0.8055555555555556,\n",
       " 0.9,\n",
       " 0.7692307692307693,\n",
       " 0.7222222222222222,\n",
       " 0.6944444444444444,\n",
       " 0.7631578947368421,\n",
       " 0.7105263157894737,\n",
       " 0.6486486486486487,\n",
       " 0.6756756756756757,\n",
       " 0.5277777777777778,\n",
       " 0.6388888888888888,\n",
       " 0.6388888888888888,\n",
       " 0.6052631578947368,\n",
       " 0.625,\n",
       " 0.6216216216216216,\n",
       " 0.65,\n",
       " 0.7027027027027027,\n",
       " 0.7027027027027027,\n",
       " 0.7222222222222222,\n",
       " 0.6666666666666666,\n",
       " 0.7894736842105263,\n",
       " 0.6944444444444444,\n",
       " 0.6666666666666666,\n",
       " 0.7297297297297297,\n",
       " 0.725,\n",
       " 0.8157894736842105,\n",
       " 0.6578947368421053,\n",
       " 0.6944444444444444,\n",
       " 0.725,\n",
       " 0.7631578947368421,\n",
       " 0.6944444444444444,\n",
       " 0.6666666666666666,\n",
       " 0.8378378378378378,\n",
       " 0.7692307692307693,\n",
       " 0.6410256410256411,\n",
       " 0.7297297297297297,\n",
       " 0.7441860465116279,\n",
       " 0.6111111111111112,\n",
       " 0.6944444444444444,\n",
       " 0.6111111111111112,\n",
       " 0.7435897435897436,\n",
       " 0.7777777777777778,\n",
       " 0.75,\n",
       " 0.7209302325581395,\n",
       " 0.6944444444444444,\n",
       " 0.8055555555555556,\n",
       " 0.6052631578947368,\n",
       " 0.7906976744186046,\n",
       " 0.6756756756756757,\n",
       " 0.75,\n",
       " 0.7,\n",
       " 0.6388888888888888,\n",
       " 0.65,\n",
       " 0.7,\n",
       " 0.7222222222222222,\n",
       " 0.6923076923076923,\n",
       " 0.7435897435897436,\n",
       " 0.725,\n",
       " 0.8108108108108109,\n",
       " 0.6578947368421053,\n",
       " 0.7368421052631579,\n",
       " 0.6944444444444444,\n",
       " 0.6388888888888888,\n",
       " 0.7631578947368421,\n",
       " 0.7631578947368421,\n",
       " 0.7435897435897436,\n",
       " 0.7894736842105263,\n",
       " 0.7380952380952381,\n",
       " 0.5277777777777778,\n",
       " 0.6923076923076923,\n",
       " 0.6388888888888888,\n",
       " 0.6904761904761905,\n",
       " 0.55,\n",
       " 0.7631578947368421,\n",
       " 0.7368421052631579,\n",
       " 0.5789473684210527,\n",
       " 0.6111111111111112,\n",
       " 0.7027027027027027,\n",
       " 0.75,\n",
       " 0.6842105263157895,\n",
       " 0.5675675675675675,\n",
       " 0.6486486486486487,\n",
       " 0.7894736842105263,\n",
       " 0.7837837837837838,\n",
       " 0.7380952380952381,\n",
       " 0.6842105263157895,\n",
       " 0.6744186046511628,\n",
       " 0.6388888888888888,\n",
       " 0.7222222222222222,\n",
       " 0.7368421052631579,\n",
       " 0.6578947368421053,\n",
       " 0.6756756756756757,\n",
       " 0.6756756756756757,\n",
       " 0.6388888888888888,\n",
       " 0.6666666666666666,\n",
       " 0.6216216216216216,\n",
       " 0.7560975609756098,\n",
       " 0.7222222222222222,\n",
       " 0.7297297297297297,\n",
       " 0.7380952380952381,\n",
       " 0.6388888888888888,\n",
       " 0.6666666666666666,\n",
       " 0.85,\n",
       " 0.5277777777777778,\n",
       " 0.7222222222222222,\n",
       " 0.627906976744186,\n",
       " 0.7567567567567568,\n",
       " 0.5555555555555556,\n",
       " 0.7560975609756098,\n",
       " 0.6923076923076923,\n",
       " 0.7894736842105263,\n",
       " 0.7777777777777778,\n",
       " 0.6111111111111112,\n",
       " 0.6756756756756757,\n",
       " 0.6216216216216216,\n",
       " 0.7142857142857143,\n",
       " 0.6944444444444444,\n",
       " 0.75,\n",
       " 0.631578947368421,\n",
       " 0.6666666666666666,\n",
       " 0.7894736842105263,\n",
       " 0.7222222222222222,\n",
       " 0.6944444444444444,\n",
       " 0.7105263157894737,\n",
       " 0.7297297297297297,\n",
       " 0.7894736842105263,\n",
       " 0.725,\n",
       " 0.6842105263157895,\n",
       " 0.6666666666666666,\n",
       " 0.675,\n",
       " 0.7837837837837838,\n",
       " 0.7567567567567568,\n",
       " 0.6756756756756757,\n",
       " 0.6578947368421053,\n",
       " 0.6756756756756757,\n",
       " 0.6756756756756757,\n",
       " 0.8292682926829268,\n",
       " 0.8048780487804879,\n",
       " 0.7692307692307693,\n",
       " 0.7380952380952381,\n",
       " 0.7837837837837838,\n",
       " 0.7027027027027027,\n",
       " 0.775,\n",
       " 0.7105263157894737,\n",
       " 0.7435897435897436,\n",
       " 0.625,\n",
       " 0.7567567567567568,\n",
       " 0.6666666666666666,\n",
       " 0.7380952380952381,\n",
       " 0.7073170731707317,\n",
       " 0.7297297297297297,\n",
       " 0.6842105263157895,\n",
       " 0.6666666666666666,\n",
       " 0.6944444444444444,\n",
       " 0.675,\n",
       " 0.6388888888888888,\n",
       " 0.6923076923076923,\n",
       " 0.7105263157894737,\n",
       " 0.6842105263157895,\n",
       " 0.7804878048780488,\n",
       " 0.35135135135135137,\n",
       " 0.717948717948718,\n",
       " 0.717948717948718,\n",
       " 0.631578947368421,\n",
       " 0.75,\n",
       " 0.7317073170731707,\n",
       " 0.7105263157894737,\n",
       " 0.717948717948718,\n",
       " 0.5789473684210527,\n",
       " 0.7027027027027027,\n",
       " 0.7368421052631579,\n",
       " 0.6923076923076923,\n",
       " 0.7,\n",
       " 0.7560975609756098,\n",
       " 0.6842105263157895,\n",
       " 0.6111111111111112,\n",
       " 0.675,\n",
       " 0.7105263157894737,\n",
       " 0.7435897435897436,\n",
       " 0.7297297297297297,\n",
       " 0.5675675675675675,\n",
       " 0.6756756756756757,\n",
       " 0.7567567567567568,\n",
       " 0.75,\n",
       " 0.7,\n",
       " 0.7317073170731707,\n",
       " 0.6756756756756757,\n",
       " 0.6829268292682927,\n",
       " 0.6111111111111112,\n",
       " 0.7631578947368421,\n",
       " 0.7567567567567568,\n",
       " 0.6756756756756757,\n",
       " 0.7435897435897436,\n",
       " 0.7560975609756098,\n",
       " 0.7105263157894737,\n",
       " 0.7027027027027027,\n",
       " 0.6666666666666666,\n",
       " 0.7297297297297297,\n",
       " 0.6923076923076923,\n",
       " 0.6756756756756757,\n",
       " 0.6388888888888888,\n",
       " 0.6578947368421053,\n",
       " 0.6666666666666666,\n",
       " 0.6756756756756757,\n",
       " 0.7297297297297297,\n",
       " 0.6410256410256411,\n",
       " 0.7567567567567568,\n",
       " 0.7441860465116279,\n",
       " 0.7142857142857143,\n",
       " 0.725,\n",
       " 0.7027027027027027,\n",
       " 0.7435897435897436,\n",
       " 0.75,\n",
       " 0.6666666666666666,\n",
       " 0.6944444444444444,\n",
       " 0.6666666666666666,\n",
       " 0.775,\n",
       " 0.7,\n",
       " 0.6216216216216216,\n",
       " 0.7837837837837838,\n",
       " 0.6388888888888888,\n",
       " 0.6666666666666666,\n",
       " 0.4444444444444444,\n",
       " 0.6756756756756757,\n",
       " 0.6923076923076923,\n",
       " 0.7692307692307693,\n",
       " 0.7777777777777778,\n",
       " 0.7,\n",
       " 0.7368421052631579,\n",
       " 0.6666666666666666,\n",
       " 0.7027027027027027,\n",
       " 0.6666666666666666,\n",
       " 0.6842105263157895,\n",
       " 0.717391304347826,\n",
       " 0.725,\n",
       " 0.6578947368421053,\n",
       " 0.7027027027027027,\n",
       " 0.6923076923076923,\n",
       " 0.675,\n",
       " 0.7222222222222222,\n",
       " 0.6666666666666666,\n",
       " 0.7105263157894737,\n",
       " 0.8048780487804879,\n",
       " 0.8,\n",
       " 0.7368421052631579,\n",
       " 0.5555555555555556,\n",
       " 0.7317073170731707,\n",
       " 0.85,\n",
       " 0.6216216216216216,\n",
       " 0.7837837837837838,\n",
       " 0.6923076923076923,\n",
       " 0.6486486486486487,\n",
       " 0.6216216216216216,\n",
       " 0.5789473684210527,\n",
       " 0.7105263157894737,\n",
       " 0.717948717948718,\n",
       " 0.6486486486486487,\n",
       " 0.6486486486486487,\n",
       " 0.6666666666666666,\n",
       " 0.7,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.7297297297297297,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.675,\n",
       " 0.7222222222222222,\n",
       " 0.5897435897435898,\n",
       " 0.5945945945945946,\n",
       " 0.6486486486486487,\n",
       " 0.6944444444444444,\n",
       " 0.6944444444444444,\n",
       " 0.8205128205128205,\n",
       " 0.6388888888888888,\n",
       " 0.7,\n",
       " 0.6410256410256411,\n",
       " 0.7297297297297297,\n",
       " 0.5675675675675675,\n",
       " 0.6923076923076923,\n",
       " 0.6923076923076923,\n",
       " 0.625,\n",
       " 0.6578947368421053,\n",
       " 0.7297297297297297,\n",
       " 0.8108108108108109,\n",
       " 0.6486486486486487,\n",
       " 0.6666666666666666,\n",
       " 0.5526315789473685,\n",
       " 0.6976744186046512,\n",
       " 0.5555555555555556,\n",
       " 0.4722222222222222,\n",
       " 0.7894736842105263,\n",
       " 0.85,\n",
       " ...]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Jaccard Similarity\"]=values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments</th>\n",
       "      <th>Average Score</th>\n",
       "      <th>Jaccard Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>moved uk end august got virgin media broadband...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>truly attrocious service terms broadband custo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.702703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard cancel contract. phone 2 hours t o spend ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pay 350mbps package managed 250mbps upload 34 ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worst customer service: -the bots ask irreleva...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Comments  Average Score  \\\n",
       "0  moved uk end august got virgin media broadband...            1.0   \n",
       "1  truly attrocious service terms broadband custo...            1.0   \n",
       "2  hard cancel contract. phone 2 hours t o spend ...            2.0   \n",
       "3  pay 350mbps package managed 250mbps upload 34 ...            2.0   \n",
       "4  worst customer service: -the bots ask irreleva...            2.0   \n",
       "\n",
       "   Jaccard Similarity  \n",
       "0            1.000000  \n",
       "1            0.702703  \n",
       "2            0.666667  \n",
       "3            0.692308  \n",
       "4            0.692308  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments</th>\n",
       "      <th>Average Score</th>\n",
       "      <th>jaccard similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>moved uk end august got virgin media broadband...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>truly attrocious service terms broadband custo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard cancel contract. phone 2 hours t o spend ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.005985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pay 350mbps package managed 250mbps upload 34 ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.006214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worst customer service: -the bots ask irreleva...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.006214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Comments  Average Score  \\\n",
       "0  moved uk end august got virgin media broadband...            1.0   \n",
       "1  truly attrocious service terms broadband custo...            1.0   \n",
       "2  hard cancel contract. phone 2 hours t o spend ...            2.0   \n",
       "3  pay 350mbps package managed 250mbps upload 34 ...            2.0   \n",
       "4  worst customer service: -the bots ask irreleva...            2.0   \n",
       "\n",
       "   jaccard similarity  \n",
       "0            0.008274  \n",
       "1            0.005988  \n",
       "2            0.005985  \n",
       "3            0.006214  \n",
       "4            0.006214  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df[\"Average Score\"]\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.340, random_state=0, stratify=y)\n",
    "#60 training, 20 validation, 20 testing\n",
    "X_val, X_test, y_val, y_test =train_test_split(X_temp, y_temp, test_size = 0.5, random_state=0, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "        Embedding(max_words, embedding_dim, input_length=X.shape[1]),#mask=0 so we can handle inputs of variable lengths\n",
    "        #now we have a vector of numbers a nn can comprehend\n",
    "        tf.keras.layers.SpatialDropout1D(0.2),\n",
    "        tf.keras.layers.LSTM(32),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dropout(0.4),\n",
    "        Dense(4, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(RMSprop(learning_rate=0.001), \n",
    "             loss = SparseCategoricalCrossentropy(), #categorical cross entropy as multi classification problem\n",
    "                metrics=[\"sparse_categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 5s 43ms/step - loss: 1.3882 - sparse_categorical_accuracy: 0.1490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3882297277450562, 0.1490401327610016]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_train, y_train) #evaluate performance of model without training it firs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3b44d0901b27b90b29836124934e882c64ed863e8408c20b31f73c13ca8ef04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
